{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Importing libraries\n",
        "\n"
      ],
      "metadata": {
        "id": "ZACfEKrxxyvu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rz0dUkFMKvjA",
        "outputId": "1668877d-5576-4602-9f6c-3926825e623c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.5.13)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.26.15)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle) (2022.12.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.65.0)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting zip\n",
            "  Downloading zip-0.0.2.tar.gz (3.0 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting Flask-Admin>=1.0.4\n",
            "  Downloading Flask_Admin-1.6.1-py3-none-any.whl (7.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m54.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Flask-Bootstrap>=2.2.2-1\n",
            "  Downloading Flask-Bootstrap-3.3.7.1.tar.gz (456 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m456.4/456.4 kB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting Flask-Cache>=0.10.1\n",
            "  Downloading Flask-Cache-0.13.1.tar.gz (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.8/45.8 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting Flask-FlatPages>=0.3\n",
            "  Downloading Flask_FlatPages-0.8.1-py2.py3-none-any.whl (10 kB)\n",
            "Collecting Flask-Gravatar>=0.2.4\n",
            "  Downloading Flask_Gravatar-0.5.0-py2.py3-none-any.whl (7.5 kB)\n",
            "Collecting Flask-Login>=0.1.3\n",
            "  Downloading Flask_Login-0.6.2-py3-none-any.whl (17 kB)\n",
            "Collecting Flask-Mail>=0.7.4\n",
            "  Downloading Flask-Mail-0.9.1.tar.gz (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting Flask-PyMongo>=0.2.1\n",
            "  Downloading Flask_PyMongo-2.3.0-py2.py3-none-any.whl (12 kB)\n",
            "Collecting Flask-Restless>=0.9.1\n",
            "  Downloading Flask-Restless-0.17.0.tar.gz (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.7/42.7 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting Flask-SQLAlchemy>=0.16\n",
            "  Downloading Flask_SQLAlchemy-3.0.3-py3-none-any.whl (24 kB)\n",
            "Collecting Flask-Themes>=0.1.3\n",
            "  Downloading Flask-Themes-0.1.3.tar.gz (9.7 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting Flask-Uploads>=0.1.3\n",
            "  Downloading Flask-Uploads-0.2.1.tar.gz (7.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting Flask-WTF>=0.8.2\n",
            "  Downloading Flask_WTF-1.1.1-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: Flask>=0.9 in /usr/local/lib/python3.10/dist-packages (from zip) (2.2.4)\n",
            "Collecting frozen-flask\n",
            "  Downloading Frozen_Flask-0.18-py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: Jinja2>=2.6 in /usr/local/lib/python3.10/dist-packages (from zip) (3.1.2)\n",
            "Requirement already satisfied: Markdown>=2.2.1 in /usr/local/lib/python3.10/dist-packages (from zip) (3.4.3)\n",
            "Requirement already satisfied: PyYAML>=3.11 in /usr/local/lib/python3.10/dist-packages (from zip) (6.0)\n",
            "Requirement already satisfied: SQLAlchemy>=0.8.0b2 in /usr/local/lib/python3.10/dist-packages (from zip) (2.0.10)\n",
            "Requirement already satisfied: Sphinx>=1.3.1 in /usr/local/lib/python3.10/dist-packages (from zip) (3.5.4)\n",
            "Collecting WTForms>=1.0.3\n",
            "  Downloading WTForms-3.0.1-py3-none-any.whl (136 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m136.5/136.5 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Werkzeug>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from zip) (2.3.0)\n",
            "Collecting argparse>=1.2.1\n",
            "  Downloading argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n",
            "Collecting blinker>=1.2\n",
            "  Downloading blinker-1.6.2-py3-none-any.whl (13 kB)\n",
            "Collecting bumpversion>=0.5.3\n",
            "  Downloading bumpversion-0.6.0-py2.py3-none-any.whl (8.4 kB)\n",
            "Requirement already satisfied: click>=6.3 in /usr/local/lib/python3.10/dist-packages (from zip) (8.1.3)\n",
            "Collecting colorama>=0.3.7\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Collecting coverage>=4.0\n",
            "  Downloading coverage-7.2.5-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (228 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m228.2/228.2 kB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cryptography>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from zip) (40.0.2)\n",
            "Collecting flake8>=2.4.1\n",
            "  Downloading flake8-6.0.0-py2.py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.8/57.8 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: networkx>=1.11 in /usr/local/lib/python3.10/dist-packages (from zip) (3.1)\n",
            "Collecting pymongo>=2.5.1\n",
            "  Downloading pymongo-4.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (492 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m492.9/492.9 kB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pytest>=2.8.3 in /usr/local/lib/python3.10/dist-packages (from zip) (7.2.2)\n",
            "Requirement already satisfied: python-dateutil>=1.5 in /usr/local/lib/python3.10/dist-packages (from zip) (2.8.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from zip) (1.16.0)\n",
            "Collecting tox>=2.1.1\n",
            "  Downloading tox-4.5.1-py3-none-any.whl (148 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.0/149.0 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting watchdog>=0.8.3\n",
            "  Downloading watchdog-3.0.0-py3-none-manylinux2014_x86_64.whl (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from zip) (0.40.0)\n",
            "Collecting wsgiref>=0.1.2\n",
            "  Downloading wsgiref-0.1.2.zip (37 kB)\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting unidecode\n",
            "  Downloading Unidecode-1.3.6-py3-none-any.whl (235 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.9/235.9 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: unidecode\n",
            "Successfully installed unidecode-1.3.6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]   Unzipping stemmers/rslp.zip.\n"
          ]
        }
      ],
      "source": [
        "!pip install kaggle\n",
        "!pip install zip\n",
        "!pip install unidecode\n",
        "import json\n",
        "import os, sys, stat\n",
        "import shutil\n",
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "import numpy as np\n",
        "nltk.download('stopwords')\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')\n",
        "from nltk.stem import RSLPStemmer\n",
        "nltk.download('rslp')\n",
        "stemmer = RSLPStemmer()\n",
        "stopwords = nltk.corpus.stopwords.words('english')\n",
        "\n",
        "#ML Pre processing\n",
        "\n",
        "from sklearn import preprocessing\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#Metrics\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importing dataset"
      ],
      "metadata": {
        "id": "5dzhxLY2yIHy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kaggle class allow you to connect to kaggle and retrieve your dataset by providing your credentials json variable \"kj_object\".\n",
        "\n",
        "dumpJson() - Creates a folder path with json for kaggle API auth\n",
        "\n",
        "get_dataset() - Retrieves your kaggle dataset"
      ],
      "metadata": {
        "id": "CYeCkshe1ql8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kj_object = {\n",
        "      \"username\":\"<kaggle_username>\",\n",
        "      \"key\":\"<kaggle_api_token>\"\n",
        "  }\n",
        "\n",
        "class Kaggle():\n",
        "\n",
        "    def __init__(self, kj_object: object):\n",
        "      self.kj_object = kj_object\n",
        "\n",
        "    def dumpJson(self):\n",
        "\n",
        "    #Kaggle API Token\n",
        "\n",
        "    #Validating if path already exists\n",
        "\n",
        "      if os.path.exists('/root/.kaggle'):\n",
        "        shutil.rmtree('/root/.kaggle')\n",
        "        print(\"--> Deleting already existing 'Kaggle' repository\")\n",
        " \n",
        "      print(\"--> Creating new file at .kaggle\")\n",
        "      os.makedirs('../root/.kaggle', exist_ok = True)\n",
        "\n",
        "      #shutil.move('.kaggle', '/root/')\n",
        "      \n",
        "\n",
        "      kaggle_Json = json.dumps(self.kj_object)\n",
        "      kaggle_json_file = open('/root/.kaggle/kaggle.json', 'w')\n",
        "      kaggle_json_file.write(kaggle_Json)\n",
        "      kaggle_json_file.close()\n",
        "\n",
        "      #!mv /root/.kaggle /content/\n",
        "      os.chmod('/root/.kaggle/kaggle.json', 600) \n",
        "\n",
        "    def get_dataset(self):\n",
        "\n",
        "      !kaggle datasets download -d reihanenamdari/mental-health-corpus\n"
      ],
      "metadata": {
        "id": "1_4IoJk8K_si"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kaggle_conn = Kaggle(kj_object)"
      ],
      "metadata": {
        "id": "UASB8vZiMANo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "kaggle_conn.dumpJson()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6q0lDfItMUPL",
        "outputId": "7f408294-6866-4a67-baf2-3d9c035c1894"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--> Creating new file at .kaggle\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "kaggle_conn.get_dataset()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OyWr0JxFMe6g",
        "outputId": "343b42fd-0050-48eb-bec6-9fb164bd0b77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading mental-health-corpus.zip to /content\n",
            "\r  0% 0.00/4.74M [00:00<?, ?B/s]\r100% 4.74M/4.74M [00:00<00:00, 38.8MB/s]\n",
            "\r100% 4.74M/4.74M [00:00<00:00, 38.6MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def unzipDataset(path_from, path_target):\n",
        "\n",
        "  import zipfile\n",
        "  with zipfile.ZipFile(path_from, 'r') as zip_ref:\n",
        "    zip_ref.extractall(path_target)\n",
        "\n",
        "  os.remove(path_from)\n",
        "\n",
        "  return "
      ],
      "metadata": {
        "id": "YfNgEtLUK_oW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unzipDataset('/content/mental-health-corpus.zip', '/content/sample_data')"
      ],
      "metadata": {
        "id": "qYQEQX7RK_l_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/sample_data/mental_health.csv')"
      ],
      "metadata": {
        "id": "zQ4oxGJaK_jo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(100)"
      ],
      "metadata": {
        "id": "MPwlJIhHK_eK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "3ab84167-f5f7-4b35-c3b2-91d7ddcb7779"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 text  label\n",
              "0   dear american teens question dutch person hear...      0\n",
              "1   nothing look forward lifei dont many reasons k...      1\n",
              "2   music recommendations im looking expand playli...      0\n",
              "3   im done trying feel betterthe reason im still ...      1\n",
              "4   worried  year old girl subject domestic physic...      1\n",
              "..                                                ...    ...\n",
              "95  weird or im ambivert already tell pretty weird...      0\n",
              "96  weeks ago saved friend redflag suspended reddi...      0\n",
              "97  emo anything but songs lonely palaye royal iro...      0\n",
              "98  else dobefore begin long post amp hope take ti...      1\n",
              "99  im ready plan redflagimagine chronically ill s...      1\n",
              "\n",
              "[100 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3860bad9-311e-4b83-b5c6-2ba126414557\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>dear american teens question dutch person hear...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>nothing look forward lifei dont many reasons k...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>music recommendations im looking expand playli...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>im done trying feel betterthe reason im still ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>worried  year old girl subject domestic physic...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>weird or im ambivert already tell pretty weird...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>weeks ago saved friend redflag suspended reddi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>emo anything but songs lonely palaye royal iro...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>else dobefore begin long post amp hope take ti...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>im ready plan redflagimagine chronically ill s...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3860bad9-311e-4b83-b5c6-2ba126414557')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3860bad9-311e-4b83-b5c6-2ba126414557 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3860bad9-311e-4b83-b5c6-2ba126414557');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preparing data"
      ],
      "metadata": {
        "id": "e8JSkoCRyUOE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The class data_normalization described bellow allow you to apply some methods for preparing your dataset inputs such as: removing special characters and removing extra spaces, reducing each word to its root (word stemming) and removing stopwords.\n",
        "\n",
        "All the operations are applied on tokenized strings."
      ],
      "metadata": {
        "id": "Y_Nwdrnp2xdt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class data_normalization():\n",
        "\n",
        "  def __init__(self, dataframe):\n",
        "    self.dataframe = df\n",
        "    \n",
        "\n",
        "  def normalize_spaces(df):\n",
        "    df.text_norm = [re.sub(r\"[^a-zA-Z0-9 ]\",\"\",text) for text in df.text.values]\n",
        "    df.text_norm = [re.sub(r\"\\s+\",\" \",text) for text in df.text.values]\n",
        "\n",
        "  \n",
        "  def stemm_words(df):\n",
        "    stemmed_tokens = []\n",
        "    for sentence in df.text:\n",
        "        stemmed_tokens.append(\" \".join([stemmer.stem(i) for i in sentence.split()]))\n",
        "    # print(len(stemmed_tokens))\n",
        "    return stemmed_tokens\n",
        "\n",
        "\n",
        "  def remove_stopwords(df):\n",
        "\n",
        "    tokens_wtout_sw = []\n",
        "\n",
        "    for sentence in df:\n",
        "      sentence = ' '.join([word for word in sentence.split() if word not in stopwords])\n",
        "      tokens_wtout_sw.append(sentence)\n",
        "\n",
        "    return tokens_wtout_sw\n"
      ],
      "metadata": {
        "id": "G3AfZC1nK_Wp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stemmed_tokens = data_normalization.stemm_words(df)"
      ],
      "metadata": {
        "id": "GqA99EzrbJem"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_text_tokens = data_normalization.remove_stopwords(stemmed_tokens)"
      ],
      "metadata": {
        "id": "RzrQ_7OnfGEd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Making sure that stopwords were removed\n",
        "\n",
        "count_before_stopwords=0\n",
        "for sentence in df.text.values:\n",
        "  for word in sentence.split(' '):\n",
        "    count_before_stopwords+=1\n",
        "\n",
        "print(f'Before removing stopwords: {count_before_stopwords}')\n",
        "\n",
        "\n",
        "count_after_stopwords=0\n",
        "for sentence in df_text_tokens:\n",
        "  for word in sentence.split(' '):\n",
        "      count_after_stopwords+=1\n",
        "\n",
        "print(f'After removing stopwords: {count_after_stopwords}')\n"
      ],
      "metadata": {
        "id": "_7Nzv4awlMxF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b82509b-410d-47ba-e1eb-a4d26a89b80d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before removing stopwords: 2043667\n",
            "After removing stopwords: 1905141\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_text_tokens[:5]"
      ],
      "metadata": {
        "id": "N4Zq0cf2fZKd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03c78b4f-d205-40dd-b248-a4c7355f3d9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['de american te question dutch person heard guy get way easi thing learn age us soooo thth grad lik right guy learn math',\n",
              " 'nothing look forward lif dont many reasom keep going feel lik nothing keep going next day mak want hang',\n",
              " 'music recommendatiom im looking expand playlist usual genr alt pop minnesot hip hop steampunk vari indi genr artist peopl lik cavetown aliceband bug hunt penelop scott vari rhymesay willing explor new genresartist anything generic rap typ exclusively sex drug cool rapp rap typ pretty good pop popul coupl ye ago dunn technic genr nam anyway anyon got music recommendatiom favorit artistssong',\n",
              " 'im trying feel betterth reason im still aliv know mum devastated ev killed ev pass im still stat im going hesitat ending lif shortly aft im almost tak med go therapy nothing se help enough dont want around anymor hat feeling lik thil wouldnt wish upon enemy brain feel lik constantly lik static tv wont shut overthinking think im running optiom dont see living past got accepted health scienc degre dont even know wann try know im smart ment illnes hold back think cant anything im good enough need fucking help dont know anymor ive run optiom',\n",
              " 'worried ye old girl subject domestic physicalment housewithout going lot know girl know girl etc let giv brief background known girl ye liv uk liv different country kept touch electronic first girl schizophrenic host illn dad sev ang issu abus physically mentally mak serv food wash dish clean hous shout beat petty thing lik spilling wat picking toy flo threatened knif beat plat gl punch head last tim got beat around month ago one sibling get beat tried tell moth beating showed bruis moth refus believ even laughed probably fe confronting husband yell wif family treat well eith sist mean tell fath put troubl family tend isolat even rememb birthday family cold often tend alienat sinc act norm girl often feel suicid due thil inflicted selfharm cut wrist starv believ way family accept mak wors two incident lif must tell raped walking back hom night initially tell parent sometim lat polic report filed rap suffered fals pregnancy girl symptom disord lik lactating breast happened early depressed incident summ approximately family sent coupl family friend wellknown treatment advertised herb therapy accupunctur etc howev happened next terribl left alon husband wif went somewh els guy tortured instanc mad sit contain filled wat upt neck closed lid imagin kind stres panic would caus schizophrenic patient miscellan detail gt get visit psychiatrist school abl hid probl psychiatrist noted girl abl put front really well gt fiv psychiatrist past gt enjoy drawingpainting learning new languag writing po gt depressed tend victimized mentality blam probl want report abus due troubl family fac tell stopped cutting lately probl refus tell anyon abus even tri defend fath saying fault help although se extremely suicid concern physically ment abus girl subject everyday healthy environment anyon grow really wish rescued clutch belligerent controlling fath dysfunct family']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Enconding targets"
      ],
      "metadata": {
        "id": "ui8p3TS_v-aa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Labels are already encoded on dataset, but to make sure it's not going to fail let's enforce it :)"
      ],
      "metadata": {
        "id": "8VA6aRN-3oGC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lenc = preprocessing.LabelEncoder()"
      ],
      "metadata": {
        "id": "VvgHk3kIkn6p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lenc_target = lenc.fit(df.label)"
      ],
      "metadata": {
        "id": "GesFBgF6uhvh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list(lenc_target.classes_)"
      ],
      "metadata": {
        "id": "7xlfnoceScj3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b34a3a52-e2ce-43ab-e66f-a6291aff970b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Splitting data and Feature extraction"
      ],
      "metadata": {
        "id": "b-WJq-yIwD6c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vec = TfidfVectorizer(max_features=3000)\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(vec.fit_transform(df_text_tokens), df.label.values, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "G6eeK8KkuprZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "T5hCi1Dvv1ZZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model fitting"
      ],
      "metadata": {
        "id": "7LMq6PvJwH_N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "\n",
        "model_rf= RandomForestClassifier(n_estimators=10,random_state=42)"
      ],
      "metadata": {
        "id": "7lZE2gR2wM65"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict = model_rf.fit(X_train, Y_train)"
      ],
      "metadata": {
        "id": "y9c3xqkqwUZG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model metrics"
      ],
      "metadata": {
        "id": "4o-6N9mWwpeW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train Accuracy  : {:.2f} %\".format(accuracy_score(model_rf.predict(X_train), Y_train)*100))\n",
        "print(\"Test Accuracy   : {:.2f} %\".format(accuracy_score(model_rf.predict(X_test), Y_test)*100))\n",
        "print(\"Precision       : {:.2f} %\".format(precision_score(model_rf.predict(X_test), Y_test,average='macro')*100))\n",
        "print(\"Recall          : {:.2f} %\".format(recall_score(model_rf.predict(X_test), Y_test,average='macro')*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oAGEvG3zweco",
        "outputId": "694ce95e-bb26-4a59-831a-11cb7fd85bec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy  : 99.35 %\n",
            "Test Accuracy   : 87.53 %\n",
            "Precision       : 87.53 %\n",
            "Recall          : 87.53 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing own string"
      ],
      "metadata": {
        "id": "Cps339lU34yf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dict_labels = {0:'Possible Mental Health Issues - NOT IDENTIFIED', 1:'Possible Mental Health Issues - IDENTIFIED'}"
      ],
      "metadata": {
        "id": "lm1wB7hGwkyw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Down bellow you can type your own strings on list \"new_input\" to test the model :)"
      ],
      "metadata": {
        "id": "T3J3FmB54CmM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_input = ['today im feeling like dont want to live... dont know why but i see no reason for being here. Good bye forever ill suicide', 'woke up in an awesome mood today', 'her atitude gave me anxiety and a deep sadness... dont want to live it again and dont even look at her face once more']\n"
      ],
      "metadata": {
        "id": "DWthUNQMxeV5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_string(inputData):\n",
        "\n",
        "  #Normalize spaces and remove specials\n",
        "  inputData = [re.sub(r\"[^a-zA-Z0-9 ]\",\"\",text) for text in inputData]\n",
        "  inputData = [re.sub(r\"\\s+\",\" \",text) for text in inputData]\n",
        "\n",
        "  # #Tokenize, stem and remove stopwords\n",
        "  tokenized_strings = []\n",
        "  for text in inputData:\n",
        "    tokenized_words = [stemmer.stem(word) for word in text.lower().split() if word not in stopwords]\n",
        "    tokenized_string = \" \".join(tokenized_words)\n",
        "    tokenized_strings.append(tokenized_string)\n",
        "\n",
        "  return tokenized_strings"
      ],
      "metadata": {
        "id": "ySYgNahYyKk5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_strings = normalize_string(new_input)"
      ],
      "metadata": {
        "id": "EYrey2_CyMy3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_strings"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OsPLMXwJ_Wlw",
        "outputId": "ea5fc101-44fd-4917-fe3f-3411b2e845c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['today im feeling lik dont want liv dont know see reason good bye forev ill suicid',\n",
              " 'wok awesom mood today',\n",
              " 'atitud gav anxiety deep sadnes dont want liv dont even look fac']"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_vec = vec.fit(df_text_tokens)"
      ],
      "metadata": {
        "id": "8ZjYtBbCzTDx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_vec_transformed = vec.transform(tokenized_strings)"
      ],
      "metadata": {
        "id": "w6xAYuhm0opb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_pred = model_rf.predict(new_vec_transformed)"
      ],
      "metadata": {
        "id": "9svNoMUc06Ma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_pred_proba = model_rf.predict_proba(new_vec_transformed)"
      ],
      "metadata": {
        "id": "oe39br8aMDT1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "for result in range (0, len(new_pred)):\n",
        "  proba = new_pred_proba[count][new_pred[result]]*100\n",
        "  print(f'Data: {tokenized_strings[result]}\\nResult: {dict_labels[new_pred[result]]}\\nConfidence:{proba: .2f}%\\n\\n')\n",
        "  count+=1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_cBXJLx2HETR",
        "outputId": "5a232d58-0e37-4229-d4e2-7bbd1aecf8c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data: today im feeling lik dont want liv dont know see reason good bye forev ill suicid\n",
            "Result: Possible Mental Health Issues - IDENTIFIED\n",
            "Confidence: 60.00%\n",
            "\n",
            "\n",
            "Data: wok awesom mood today\n",
            "Result: Possible Mental Health Issues - NOT IDENTIFIED\n",
            "Confidence: 100.00%\n",
            "\n",
            "\n",
            "Data: atitud gav anxiety deep sadnes dont want liv dont even look fac\n",
            "Result: Possible Mental Health Issues - IDENTIFIED\n",
            "Confidence: 60.00%\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}